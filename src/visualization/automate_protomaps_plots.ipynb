{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# import openslide\n",
    "import torch\n",
    "import pandas as pd\n",
    "from prototype_visualization_utils import get_panther_encoder, visualize_categorical_heatmap, get_mixture_plot, get_default_cmap\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from mil_models.tokenizer import PrototypeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Loaded config path: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs\\PANTHER_fa_pt\\config.json\n",
      "üìå Loaded config_dict from JSON: {'in_dim': 1024, 'n_classes': 2, 'heads': 1, 'em_iter': 1, 'tau': 0.001, 'ot_eps': 0.1, 'n_fc_layers': 0, 'dropout': 0.25, 'out_type': 'allcat', 'out_size': 8, 'load_proto': False, 'proto_path': '.', 'fix_proto': False}\n",
      "Loading prototypes from C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\prototypes\\prototypes_c16_uni_kmeans_num_1.0e+06.pkl\n"
     ]
    }
   ],
   "source": [
    "### Loading PANTHER Encoder\n",
    "proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\prototypes\\prototypes_c16_uni_kmeans_num_1.0e+06.pkl' # 5x uni\n",
    "# proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_10x_k=0\\prototypes\\prototypes_c16_uniextracted_mag10x_patch224_fp_kmeans_num_1.0e+06.pkl' # 10x uni\n",
    "# proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_2.5x_k=0\\prototypes\\prototypes_c16_uniextracted_mag2.5x_patch224_fp_kmeans_num_1.0e+06.pkl' # 2.5x uni\n",
    "# , model_config='PANTHER_fa_pt' out_type='allcat', \n",
    "panther_encoder = get_panther_encoder(in_dim=1024, p=16, proto_path=proto_path, config_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs', model_config='PANTHER_fa_pt', out_type='allcat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating proto maps + mixture plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 test slides.\n",
      "Processing FA 56B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2569\n",
      "Processing FA 57B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.9535\n",
      "Processing FA 58B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.4151\n",
      "Processing FA 59B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.0455\n",
      "Processing FA 60 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1538\n",
      "Processing FA 61 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.8015\n",
      "Processing FA 62 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7867\n",
      "Processing FA 63 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1525\n",
      "Processing FA 64 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2711\n",
      "Processing FA 65 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3024\n",
      "Processing FA 66 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3469\n",
      "Processing FA 67 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1821\n",
      "Processing FA 68 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7813\n",
      "Processing FA 70 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.5744\n",
      "Processing FA 71 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.6366\n",
      "Processing FA 73 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.0767\n",
      "Processing FA 73 B1...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.8813\n",
      "Processing FA 73 B2...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2011\n",
      "Processing FA 74 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5046\n",
      "Processing FA 75 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.4903\n",
      "Processing FA 76 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2416\n",
      "Processing FA 77 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2196\n",
      "Processing FA 78 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5188\n",
      "Processing FA 85 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3157\n",
      "Processing FA 86 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7712\n",
      "Processing PT 35 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5027\n",
      "Processing PT 36 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.2063\n",
      "Processing PT 37 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3246\n",
      "Processing PT 39 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2099\n",
      "Processing PT 40 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1913\n",
      "Processing PT 41 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2482\n",
      "Processing PT 42 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3354\n",
      "Processing PT 52 B...\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5979\n",
      "‚úÖ All test visualizations saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from prototype_visualization_utils import get_default_cmap, get_mixture_plot\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "feats_h5_dir = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\uniextracted_mag5x_patch224_fp\\feats_h5'\n",
    "save_root = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations'\n",
    "test_csv_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\test.csv'  # <-- your CSV path\n",
    "\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Load test slide list\n",
    "# -----------------------\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "test_slides = set(df_test['slide_id'].tolist())  # no normalization\n",
    "\n",
    "print(f\"Found {len(df_test)} test slides.\")\n",
    "\n",
    "# -----------------------\n",
    "# Settings\n",
    "# -----------------------\n",
    "patch_size = 224\n",
    "alpha = 1\n",
    "scale = 0.25\n",
    "\n",
    "# -----------------------\n",
    "# Loop through features\n",
    "# -----------------------\n",
    "for fname in os.listdir(feats_h5_dir):\n",
    "    if not fname.endswith('.h5'):\n",
    "        continue\n",
    "\n",
    "    slide_id = fname.replace('.h5', '')\n",
    "    if slide_id not in test_slides:\n",
    "        continue  # Skip if not in test set\n",
    "\n",
    "    slide_dir = os.path.join(save_root, slide_id)\n",
    "    if os.path.exists(slide_dir):\n",
    "        print(f\"‚è≠ Skipping {slide_id} (already exists)\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(slide_dir, exist_ok=True)\n",
    "    h5_path = os.path.join(feats_h5_dir, fname)\n",
    "    print(f\"Processing {slide_id}...\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Load features & coords\n",
    "    # -----------------------\n",
    "    with h5py.File(h5_path, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # -----------------------\n",
    "    # Inference\n",
    "    # -----------------------\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()\n",
    "        out = info['repr']\n",
    "\n",
    "        tokenizer = PrototypeTokenizer(out_type='allcat', p=qq.shape[1])\n",
    "        mus, pis, sigmas = tokenizer.forward(out)\n",
    "        mus = mus[0].detach().cpu().numpy()\n",
    "        cluster_labels = qq.argmax(axis=1)\n",
    "\n",
    "    # -----------------------\n",
    "    # Prototype map\n",
    "    # -----------------------\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    coords -= np.array([x_min, y_min])\n",
    "    max_x, max_y = coords.max(axis=0) + patch_size\n",
    "    canvas_w, canvas_h = int(max_x), int(max_y)\n",
    "\n",
    "    canvas = Image.new('RGBA', (canvas_w, canvas_h), (255, 255, 255, 255))\n",
    "    draw = ImageDraw.Draw(canvas, 'RGBA')\n",
    "    cmap = get_default_cmap(int(cluster_labels.max()) + 1)\n",
    "\n",
    "    for (x, y), label in zip(coords, cluster_labels):\n",
    "        color = cmap[label]\n",
    "        rgba = color + (int(255 * alpha),)\n",
    "        draw.rectangle([x, y, x + patch_size, y + patch_size], fill=rgba)\n",
    "\n",
    "    if scale < 1.0:\n",
    "        canvas = canvas.resize((int(canvas_w * scale), int(canvas_h * scale)))\n",
    "    canvas.save(os.path.join(slide_dir, 'prototype_map.png'))\n",
    "\n",
    "    # -----------------------\n",
    "    # Mixture plot\n",
    "    # -----------------------\n",
    "    mixture_plot = get_mixture_plot(mus)\n",
    "    mixture_plot.savefig(os.path.join(slide_dir, 'mixture_plot.png'), bbox_inches='tight')\n",
    "    plt.close(mixture_plot)\n",
    "\n",
    "print(\"‚úÖ All test visualizations saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debugging my proto map code that works on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from prototype_visualization_utils import get_default_cmap, get_mixture_plot\n",
    "\n",
    "# Setup paths\n",
    "feats_h5_dir = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide'\n",
    "save_root = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations'\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "# Settings\n",
    "patch_size = 224\n",
    "alpha = 1\n",
    "scale = 0.25\n",
    "\n",
    "# Loop through all h5 feature files\n",
    "for fname in os.listdir(feats_h5_dir):\n",
    "    if not fname.endswith('.h5'):\n",
    "        continue\n",
    "\n",
    "    slide_id = fname.replace('.h5', '').replace(' ', '_')\n",
    "    h5_path = os.path.join(feats_h5_dir, fname)\n",
    "    slide_dir = os.path.join(save_root, slide_id)\n",
    "    os.makedirs(slide_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing {slide_id}...\")\n",
    "\n",
    "    # Load features and coords\n",
    "    with h5py.File(h5_path, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # Inference\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()\n",
    "        print('qq.shape before tokenizer', qq.shape)  # debug\n",
    "        print('qq before tokenizer', qq)  # debug\n",
    "        out = info['repr']\n",
    "        print('out.shape', out.shape)  # debug\n",
    "        print('out before tokenizer', out)  # debug\n",
    "\n",
    "        tokenizer = PrototypeTokenizer(out_type='allcat', p=qq.shape[1])\n",
    "        mus, pis, sigmas = tokenizer.forward(out)\n",
    "        print('mus.shape', mus.shape)  # debug\n",
    "        print('pis.shape', pis.shape)  # debug\n",
    "        print('sigmas.shape', sigmas.shape)  # debug\n",
    "        print('mus before detach', mus)  # debug\n",
    "        mus = mus[0].detach().cpu().numpy()\n",
    "        print('mus after detach', mus)  # debug\n",
    "        cluster_labels = qq.argmax(axis=1)\n",
    "        print('cluster_labels.shape', cluster_labels.shape)  # debug\n",
    "        print('cluster_labels before detach', cluster_labels)  # debug\n",
    "\n",
    "for i in range(min(5, len(qq))):\n",
    "    coord = coords[i]\n",
    "    scores = qq[i]\n",
    "    max_idx = scores.argmax()\n",
    "    print(f\"Patch {i} @ coord {tuple(coord)} ‚Üí max proto: {max_idx}, score: {scores[max_idx]:.4f}, full: {np.round(scores, 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting top 4 patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_k_patches_per_prototype_from_qq(\n",
    "    h5_feats_fpath,\n",
    "    patch_dir,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224,\n",
    "    save_path=None\n",
    "):\n",
    "    import glob\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import h5py\n",
    "    import os\n",
    "\n",
    "    # Load patch-level features\n",
    "    with h5py.File(h5_feats_fpath, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # Get prototype assignments\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()  # shape: (N, p)\n",
    "\n",
    "    n_patches, n_protos = qq.shape\n",
    "\n",
    "    # Select top-k patches per prototype (skip inactive prototypes)\n",
    "    proto_to_indices = {}\n",
    "    for proto in range(n_protos):\n",
    "        proto_scores = qq[:, proto]\n",
    "        if np.max(proto_scores) < 1e-5:  # Skip prototypes with no significant activation\n",
    "            continue\n",
    "\n",
    "        nonzero_indices = np.where(proto_scores > 1e-3)[0]\n",
    "        if len(nonzero_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        sorted_indices = nonzero_indices[np.argsort(-proto_scores[nonzero_indices])]\n",
    "        proto_to_indices[proto] = sorted_indices[:top_k]\n",
    "\n",
    "    active_protos = sorted(proto_to_indices.keys())\n",
    "    if len(active_protos) == 0:\n",
    "        print(\"‚ö†Ô∏è No active prototypes found in this slide.\")\n",
    "        return\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(len(active_protos), top_k, figsize=(top_k * 3, len(active_protos) * 3))\n",
    "    if len(active_protos) == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "    for row_idx, proto_idx in enumerate(active_protos):\n",
    "        indices = proto_to_indices[proto_idx]\n",
    "        for col_idx in range(top_k):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            if col_idx >= len(indices):\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch_idx = indices[col_idx]\n",
    "            x, y = coords[patch_idx]\n",
    "\n",
    "            pattern = f'*_x{int(x)}_y{int(y)}.npy'\n",
    "            matches = glob.glob(os.path.join(patch_dir, pattern))\n",
    "            if not matches:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch = np.load(matches[0])\n",
    "            ax.imshow(patch.astype(np.uint8))\n",
    "            if col_idx == 0:\n",
    "                ax.set_title(f'Proto {proto_idx}')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Saved top-k patches visualization to {save_path}\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating 16x8 plot (top 4 + 4 random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "def visualize_top_k_patches_per_prototype_from_qq(\n",
    "    h5_feats_fpath,\n",
    "    patch_dir,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224,\n",
    "    save_path=None\n",
    "):\n",
    "    # Load patch-level features\n",
    "    with h5py.File(h5_feats_fpath, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # Get prototype assignments\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()  # shape: (N, p)\n",
    "\n",
    "    n_patches, n_protos = qq.shape\n",
    "    total_k = top_k * 2  # 4 top + 4 random\n",
    "\n",
    "    # Select 4 top + 4 random per prototype\n",
    "    proto_to_indices = {}\n",
    "    for proto in range(n_protos):\n",
    "        proto_scores = qq[:, proto]\n",
    "        if np.max(proto_scores) < 1e-5:\n",
    "            continue\n",
    "\n",
    "        nonzero_indices = np.where(proto_scores > 1e-3)[0]\n",
    "        if len(nonzero_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        sorted_indices = nonzero_indices[np.argsort(-proto_scores[nonzero_indices])]\n",
    "        top_indices = sorted_indices[:top_k]\n",
    "\n",
    "        remaining = list(set(nonzero_indices) - set(top_indices))\n",
    "        if len(remaining) >= top_k:\n",
    "            random_indices = random.sample(remaining, top_k)\n",
    "        else:\n",
    "            random_indices = remaining\n",
    "\n",
    "        combined_indices = list(top_indices) + list(random_indices)\n",
    "        proto_to_indices[proto] = combined_indices\n",
    "\n",
    "    active_protos = sorted(proto_to_indices.keys())\n",
    "    if len(active_protos) == 0:\n",
    "        print(\"‚ö†Ô∏è No active prototypes found in this slide.\")\n",
    "        return\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(len(active_protos), total_k, figsize=(total_k * 2.5, len(active_protos) * 2.5))\n",
    "    if len(active_protos) == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "    for row_idx, proto_idx in enumerate(active_protos):\n",
    "        indices = proto_to_indices[proto_idx]\n",
    "        for col_idx in range(total_k):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            if col_idx >= len(indices):\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch_idx = indices[col_idx]\n",
    "            x, y = coords[patch_idx]\n",
    "            pattern = f'*_x{int(x)}_y{int(y)}.npy'\n",
    "            matches = glob.glob(os.path.join(patch_dir, pattern))\n",
    "\n",
    "            if not matches:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch = np.load(matches[0])\n",
    "            ax.imshow(patch.astype(np.uint8))\n",
    "            if col_idx == 0:\n",
    "                ax.set_title(f'Proto {proto_idx}')\n",
    "            elif col_idx == top_k:\n",
    "                ax.set_title('‚Üì Random')\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"‚úÖ Saved patch visualization to: {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 x 16 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, h5py, torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_top_k_patches_per_prototype_from_qq(\n",
    "    h5_feats_fpath,\n",
    "    patch_dir,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224,\n",
    "    save_path=None\n",
    "):\n",
    "    # --- load features ---\n",
    "    with h5py.File(h5_feats_fpath, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.tensor(h5['features'][:])\n",
    "\n",
    "    # --- get assignments ---\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()  # (N_patches, N_protos)\n",
    "\n",
    "    n_patches, n_protos = qq.shape\n",
    "    total_k = top_k * 2  # top + random rows\n",
    "\n",
    "    # --- select patches per proto (top_k + random_k) ---\n",
    "    proto_to_indices = {}\n",
    "    for proto in range(n_protos):\n",
    "        ps = qq[:, proto]\n",
    "        if ps.max() < 1e-5:\n",
    "            continue\n",
    "        nz = np.where(ps > 1e-3)[0]\n",
    "        if len(nz) == 0:\n",
    "            continue\n",
    "        sorted_idx = nz[np.argsort(-ps[nz])]\n",
    "        top_idx = list(sorted_idx[:top_k])\n",
    "        remain = list(set(nz) - set(top_idx))\n",
    "        rand_idx = random.sample(remain, min(top_k, len(remain)))\n",
    "        proto_to_indices[proto] = top_idx + rand_idx\n",
    "\n",
    "    # active_protos = sorted(proto_to_indices.keys())\n",
    "    # if not active_protos:\n",
    "    #     print(\"‚ö†Ô∏è No active prototypes found in this slide.\")\n",
    "    #     return\n",
    "\n",
    "    all_protos = list(range(n_protos))  # fixed proto order\n",
    "    fig, axs = plt.subplots(total_k, n_protos,\n",
    "                            figsize=(n_protos * 2, total_k * 2))\n",
    "\n",
    "    for col, proto in enumerate(all_protos):\n",
    "        indices = proto_to_indices.get(proto, [])\n",
    "        for row in range(total_k):\n",
    "            ax = axs[row, col]\n",
    "            if row >= len(indices):\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "    # # --- make grid: rows = total_k (patches), cols = prototypes ---\n",
    "    # n_cols = len(active_protos)\n",
    "    # fig, axs = plt.subplots(total_k, n_cols,\n",
    "    #                         figsize=(n_cols * 2, total_k * 2))\n",
    "    # if total_k == 1: axs = np.expand_dims(axs, 0)\n",
    "    # if n_cols == 1:  axs = np.expand_dims(axs, 1)\n",
    "\n",
    "    # for col, proto in enumerate(active_protos):\n",
    "    #     indices = proto_to_indices[proto]\n",
    "    #     for row in range(total_k):\n",
    "    #         ax = axs[row, col]\n",
    "    #         if row >= len(indices):\n",
    "    #             ax.axis('off')\n",
    "    #             continue\n",
    "\n",
    "            patch_idx = indices[row]\n",
    "            x, y = coords[patch_idx]\n",
    "            pattern = f'*_x{int(x)}_y{int(y)}.npy'\n",
    "            matches = glob.glob(os.path.join(patch_dir, pattern))\n",
    "            if not matches:\n",
    "                ax.axis('off'); continue\n",
    "\n",
    "            patch = np.load(matches[0]).astype(np.uint8)\n",
    "            ax.imshow(patch)\n",
    "            ax.set_xticks([]); ax.set_yticks([]); ax.axis('off')\n",
    "\n",
    "            # column titles on top row\n",
    "            if row == 0:\n",
    "                ax.set_title(f'Proto {proto}', fontsize=12, pad=4)\n",
    "\n",
    "            # put a \"Random\" row label in the first column, but as free text\n",
    "            if row == top_k:\n",
    "                any_col = 0  # works even if this col is empty; position still exists\n",
    "                row_pos = axs[top_k, any_col].get_position()\n",
    "                y_center = (row_pos.y0 + row_pos.y1) / 2.0\n",
    "\n",
    "                # left margin: match your subplots_adjust(left=...)\n",
    "                fig.text(0.015, y_center, 'Random ‚Üì', ha='left', va='center',\n",
    "                        fontsize=12, fontweight='bold')\n",
    "                # # text in axis coordinates, slightly outside on the left\n",
    "                # ax.text(-0.15, 0.5, 'Random ‚Üì',\n",
    "                #         transform=ax.transAxes, va='center', ha='right',\n",
    "                #         fontsize=12, fontweight='bold')\n",
    "\n",
    "    # keep margins so the left-side \"Random\" text isn't clipped\n",
    "    plt.subplots_adjust(left=0.06, right=0.995, top=0.95, bottom=0.03,\n",
    "                        wspace=0.02, hspace=0.04)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"‚úÖ Saved patch visualization to: {save_path}\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def run_all_patch_visualizations(\n",
    "    feats_h5_dir,\n",
    "    patch_root,\n",
    "    csv_path,\n",
    "    save_root,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224\n",
    "):\n",
    "    \"\"\"\n",
    "    Automates prototype patch visualization across slides using Panther qq assignments.\n",
    "\n",
    "    Args:\n",
    "        feats_h5_dir (str): Path to the directory containing .h5 feature files.\n",
    "        patch_root (str): Root path to the patch directory (organized by magnification/class).\n",
    "        csv_path (str): Path to CSV file with columns ['Filename', 'Class', 'Magnification'].\n",
    "        save_root (str): Directory where visualization images will be saved.\n",
    "        panther_encoder (torch.nn.Module): Trained Panther encoder model.\n",
    "        top_k (int): Number of top patches to visualize per prototype.\n",
    "        patch_size (int): Size of each patch (default: 224).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['Filename'] = df['Filename'].str.strip()\n",
    "\n",
    "    for h5_file in os.listdir(feats_h5_dir):\n",
    "        if not h5_file.endswith('.h5'):\n",
    "            continue\n",
    "\n",
    "        slide_id = h5_file.replace('.h5', '').strip()\n",
    "\n",
    "        row = df[df['Filename'] == slide_id]\n",
    "        if row.empty:\n",
    "            print(f\"‚ö†Ô∏è Slide {slide_id} not found in metadata CSV.\")\n",
    "            continue\n",
    "\n",
    "        class_label = row['Class'].values[0]\n",
    "        magnification = row['Magnification'].values[0]\n",
    "\n",
    "        h5_feats_fpath = os.path.join(feats_h5_dir, h5_file)\n",
    "        patch_dir = os.path.join(patch_root, f\"{magnification}x\", class_label, slide_id)\n",
    "\n",
    "        if not os.path.isdir(patch_dir):\n",
    "            print(f\"‚ùå Patch directory not found: {patch_dir}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"‚úÖ Processing: {slide_id} | Class: {class_label} | Mag: {magnification}x\")\n",
    "\n",
    "        # Optional: organize outputs per slide\n",
    "        slide_dir = os.path.join(save_root, slide_id.replace(' ', '_'))\n",
    "        os.makedirs(slide_dir, exist_ok=True)\n",
    "        save_path = os.path.join(slide_dir, '8_patches.png')\n",
    "\n",
    "        try:\n",
    "            visualize_top_k_patches_per_prototype_from_qq(\n",
    "                h5_feats_fpath=h5_feats_fpath,\n",
    "                patch_dir=patch_dir,\n",
    "                panther_encoder=panther_encoder,\n",
    "                top_k=top_k,\n",
    "                patch_size=patch_size,\n",
    "                save_path=save_path\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {slide_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def run_all_patch_visualizations(\n",
    "    feats_h5_dir,\n",
    "    patch_root,\n",
    "    csv_path,  # should be your test.csv with columns: slide_id,label\n",
    "    save_root,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224\n",
    "):\n",
    "    \"\"\"\n",
    "    Automates prototype patch visualization across slides using Panther qq assignments.\n",
    "    Only processes slides listed in test CSV.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "    # Load test slides from CSV\n",
    "    df_test = pd.read_csv(csv_path)\n",
    "    df_test['slide_id'] = df_test['slide_id'].str.strip()\n",
    "    test_slides = set(df_test['slide_id'])\n",
    "\n",
    "    for h5_file in os.listdir(feats_h5_dir):\n",
    "        if not h5_file.endswith('.h5'):\n",
    "            continue\n",
    "\n",
    "        slide_id = h5_file.replace('.h5', '').strip()\n",
    "\n",
    "        # Skip if not in test set\n",
    "        if slide_id not in test_slides:\n",
    "            continue\n",
    "\n",
    "        # Infer class & mag from directory structure if needed\n",
    "        # If you don't have this in test.csv, adjust as necessary\n",
    "        # For now, we'll skip that metadata check and just assume patch dir exists\n",
    "        patch_dir = None\n",
    "        for root, dirs, files in os.walk(patch_root):\n",
    "            if os.path.basename(root) == slide_id:\n",
    "                patch_dir = root\n",
    "                break\n",
    "        if patch_dir is None:\n",
    "            print(f\"‚ùå Patch directory not found for: {slide_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"‚úÖ Processing: {slide_id}\")\n",
    "\n",
    "        # Optional: organize outputs per slide\n",
    "        slide_dir = os.path.join(save_root, slide_id)\n",
    "        os.makedirs(slide_dir, exist_ok=True)\n",
    "        save_path = os.path.join(slide_dir, '8_patches.png')\n",
    "\n",
    "        try:\n",
    "            visualize_top_k_patches_per_prototype_from_qq(\n",
    "                h5_feats_fpath=os.path.join(feats_h5_dir, h5_file),\n",
    "                patch_dir=patch_dir,\n",
    "                panther_encoder=panther_encoder,\n",
    "                top_k=top_k,\n",
    "                patch_size=patch_size,\n",
    "                save_path=save_path\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {slide_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processing: FA 56B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2569\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 56B\\8_patches.png\n",
      "‚úÖ Processing: FA 57B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.9535\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 57B\\8_patches.png\n",
      "‚úÖ Processing: FA 58B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.4151\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 58B\\8_patches.png\n",
      "‚úÖ Processing: FA 59B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.0455\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 59B\\8_patches.png\n",
      "‚úÖ Processing: FA 60 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1538\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 60 B\\8_patches.png\n",
      "‚úÖ Processing: FA 61 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.8015\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 61 B\\8_patches.png\n",
      "‚úÖ Processing: FA 62 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7867\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 62 B\\8_patches.png\n",
      "‚úÖ Processing: FA 63 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1525\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 63 B\\8_patches.png\n",
      "‚úÖ Processing: FA 64 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2711\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 64 B\\8_patches.png\n",
      "‚úÖ Processing: FA 65 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3024\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 65 B\\8_patches.png\n",
      "‚úÖ Processing: FA 66 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3469\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 66 B\\8_patches.png\n",
      "‚úÖ Processing: FA 67 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1821\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 67 B\\8_patches.png\n",
      "‚úÖ Processing: FA 68 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7813\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 68 B\\8_patches.png\n",
      "‚úÖ Processing: FA 70 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.5744\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 70 B\\8_patches.png\n",
      "‚úÖ Processing: FA 71 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.6366\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 71 B\\8_patches.png\n",
      "‚úÖ Processing: FA 73 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.0767\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 73 B\\8_patches.png\n",
      "‚úÖ Processing: FA 73 B1\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.8813\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 73 B1\\8_patches.png\n",
      "‚úÖ Processing: FA 73 B2\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2011\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 73 B2\\8_patches.png\n",
      "‚úÖ Processing: FA 74 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5046\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 74 B\\8_patches.png\n",
      "‚úÖ Processing: FA 75 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.4903\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 75 B\\8_patches.png\n",
      "‚úÖ Processing: FA 76 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2416\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 76 B\\8_patches.png\n",
      "‚úÖ Processing: FA 77 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2196\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 77 B\\8_patches.png\n",
      "‚úÖ Processing: FA 78 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5188\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 78 B\\8_patches.png\n",
      "‚úÖ Processing: FA 85 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3157\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 85 B\\8_patches.png\n",
      "‚úÖ Processing: FA 86 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.7712\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\FA 86 B\\8_patches.png\n",
      "‚úÖ Processing: PT 35 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5027\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 35 B\\8_patches.png\n",
      "‚úÖ Processing: PT 36 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 1.2063\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 36 B\\8_patches.png\n",
      "‚úÖ Processing: PT 37 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3246\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 37 B\\8_patches.png\n",
      "‚úÖ Processing: PT 39 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2099\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 39 B\\8_patches.png\n",
      "‚úÖ Processing: PT 40 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.1913\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 40 B\\8_patches.png\n",
      "‚úÖ Processing: PT 41 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.2482\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 41 B\\8_patches.png\n",
      "‚úÖ Processing: PT 42 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.3354\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 42 B\\8_patches.png\n",
      "‚úÖ Processing: PT 52 B\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 28.685 ¬± 1.907\n",
      "Covariance range: 0.100 to 0.100\n",
      "[PANTHER] Mean soft assignment entropy: 2.5979\n",
      "‚úÖ Saved patch visualization to: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations\\PT 52 B\\8_patches.png\n"
     ]
    }
   ],
   "source": [
    "run_all_patch_visualizations(\n",
    "    # feats_h5_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide',\n",
    "    feats_h5_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\uniextracted_mag5x_patch224_fp\\feats_h5',\n",
    "    patch_root=r'C:\\Users\\Vivian\\Documents\\CONCH\\all_patches\\patches_5x',\n",
    "    # csv_path=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\visualization\\slides_list.csv',\n",
    "    csv_path=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\test.csv',\n",
    "    save_root=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\test_visualizations',\n",
    "    panther_encoder=panther_encoder,\n",
    "    top_k=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting qq scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def inspect_qq_scores(slide_id, h5_dir, panther_encoder, top_k=5):\n",
    "    \"\"\"\n",
    "    Prints the prototype soft assignment (qq) scores for patches in a given slide.\n",
    "\n",
    "    Args:\n",
    "        slide_id (str): Slide ID (e.g. 'PT 41 B').\n",
    "        h5_dir (str): Directory containing .h5 feature files.\n",
    "        panther_encoder (nn.Module): Loaded Panther encoder model.\n",
    "        top_k (int): Number of top patches (by max qq) to display.\n",
    "    \"\"\"\n",
    "    # Build H5 path\n",
    "    h5_path = os.path.join(h5_dir, f\"{slide_id}.h5\")\n",
    "    if not os.path.isfile(h5_path):\n",
    "        print(f\"‚ùå H5 file not found: {h5_path}\")\n",
    "        return\n",
    "\n",
    "    # Load features and coords\n",
    "    with h5py.File(h5_path, 'r') as h5:\n",
    "        feats = torch.tensor(h5['features'][:])  # [N, D]\n",
    "        coords = h5['coords'][:]                 # [N, 2]\n",
    "\n",
    "    print(f\"‚úÖ Loaded {feats.shape[0]} patches from {slide_id}\")\n",
    "\n",
    "    # Run Panther encoder to get qq\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()  # shape: [N_patches, n_prototypes]\n",
    "\n",
    "    print(f\"qq shape: {qq.shape}\")\n",
    "    print(f\"Prototype softmax scores for first {top_k} patches:\")\n",
    "\n",
    "    # Check top_k patches with their max score and full row\n",
    "    for i in range(min(top_k, len(qq))):\n",
    "        patch_scores = qq[i]\n",
    "        max_score = patch_scores.max()\n",
    "        proto = patch_scores.argmax()\n",
    "        coord = coords[i]\n",
    "        print(f\"Patch {i} @ coord {tuple(coord)} ‚Üí max proto: {proto}, max score: {max_score:.4f}, full: {np.round(patch_scores, 3)}\")\n",
    "\n",
    "    # Check if any patch has all 1.0\n",
    "    suspicious = np.where(np.all(qq == 1.0, axis=1))[0]\n",
    "    if len(suspicious) > 0:\n",
    "        print(f\"‚ö†Ô∏è {len(suspicious)} patches have qq scores all equal to 1.0 (possible bug).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "slide_id = 'PT 41 B'\n",
    "h5_dir = r'C:\\Users\\Vivian\\Documents\\CLAM\\CLAM\\FEATURES_DIR_5x\\FEATURES_DIR_2.5x\\uniextracted_mag2x_patch224_fp\\feats_h5'\n",
    "inspect_qq_scores(slide_id, h5_dir, panther_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp fix to normalize prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# Original prototypes\n",
    "proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\prototypes\\prototypes_c16_uni_kmeans_num_1.0e+06.pkl'\n",
    "\n",
    "# Load and normalize\n",
    "with open(proto_path, 'rb') as f:\n",
    "    proto_data = pickle.load(f)\n",
    "    \n",
    "prototypes = proto_data['prototypes']\n",
    "prototypes = prototypes / np.linalg.norm(prototypes, axis=-1, keepdims=True)\n",
    "prototypes = prototypes * 1.0  # Match UNI scale\n",
    "\n",
    "# Create temporary modified prototype file\n",
    "temp_proto_path = tempfile.NamedTemporaryFile(suffix='.pkl', delete=False).name\n",
    "with open(temp_proto_path, 'wb') as f:\n",
    "    pickle.dump({'prototypes': prototypes}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Loaded config path: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs\\PANTHER_fa_pt\\config.json\n",
      "üìå Loaded config_dict from JSON: {'in_dim': 1024, 'n_classes': 2, 'heads': 1, 'em_iter': 1, 'tau': 0.001, 'ot_eps': 0.1, 'n_fc_layers': 0, 'dropout': 0.25, 'out_type': 'allcat', 'out_size': 8, 'load_proto': False, 'proto_path': '.', 'fix_proto': False}\n"
     ]
    }
   ],
   "source": [
    "### Loading PANTHER Encoder\n",
    "panther_encoder = get_panther_encoder(in_dim=1024, p=16, proto_path=temp_proto_path, config_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs', model_config='PANTHER_fa_pt', out_type='allcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Loaded config path: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs\\PANTHER_fa_pt\\config.json\n",
      "üìå Loaded config_dict from JSON: {'in_dim': 1024, 'n_classes': 2, 'heads': 1, 'em_iter': 1, 'tau': 0.001, 'ot_eps': 0.1, 'n_fc_layers': 0, 'dropout': 0.25, 'out_type': 'allcat', 'out_size': 8, 'load_proto': False, 'proto_path': '.', 'fix_proto': False}\n"
     ]
    }
   ],
   "source": [
    "def get_modified_panther_encoder():\n",
    "    # Get original encoder\n",
    "    encoder = get_panther_encoder(\n",
    "        in_dim=1024,\n",
    "        p=16,\n",
    "        proto_path=temp_proto_path,\n",
    "        config_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs',\n",
    "        model_config='PANTHER_fa_pt', \n",
    "        out_type='allcat'\n",
    "    )\n",
    "    \n",
    "    # Modify covariance scaling directly\n",
    "    with torch.no_grad():\n",
    "        encoder.panther.priors.V_.data.fill_(np.log(np.exp(10.0) - 1))  # Sets base scale to ~10.0\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "panther_encoder = get_modified_panther_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototype norms: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n",
      "Covariance range: 1.0 to 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Check prototypes\n",
    "print(\"Prototype norms:\", torch.norm(panther_encoder.panther.priors.m, dim=1))\n",
    "\n",
    "# Check covariance\n",
    "V = 0.1 * F.softplus(panther_encoder.panther.priors.V_)\n",
    "print(\"Covariance range:\", V.min().item(), \"to\", V.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "og proto map code. check why its only printing out 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototype norms: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "prototypes = panther_encoder.panther.priors.m.detach().cpu()\n",
    "print(\"Prototype norms:\", torch.norm(prototypes, dim=1))\n",
    "# Should be in similar range as your normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized feature stats - Mean: 1.3673350229836956e-09 Std: 0.9997648000717163\n",
      "feats.shape torch.Size([2136, 1024])\n",
      "\n",
      "=== map_em called ===\n",
      "\n",
      "=== mog_eval called ===\n",
      "\n",
      "Prototype norms: 1.000 ¬± 0.000\n",
      "Covariance range: 1.000 to 1.000\n",
      "Assignment scores before argmax (first 5 patches):\n",
      "tensor([[[[3.6000e-03],\n",
      "          [3.7793e-06],\n",
      "          [1.3385e-06],\n",
      "          ...,\n",
      "          [5.9588e-06],\n",
      "          [2.5002e-01],\n",
      "          [6.9040e-01]],\n",
      "\n",
      "         [[6.1873e-05],\n",
      "          [1.8758e-08],\n",
      "          [1.0963e-07],\n",
      "          ...,\n",
      "          [1.3474e-07],\n",
      "          [9.0918e-01],\n",
      "          [8.6456e-02]],\n",
      "\n",
      "         [[5.3165e-03],\n",
      "          [3.0672e-07],\n",
      "          [6.5236e-07],\n",
      "          ...,\n",
      "          [1.0985e-06],\n",
      "          [1.5935e-04],\n",
      "          [1.2452e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.2213e-05],\n",
      "          [2.3733e-03],\n",
      "          [3.6421e-06],\n",
      "          ...,\n",
      "          [9.1788e-01],\n",
      "          [1.0059e-04],\n",
      "          [2.4233e-05]],\n",
      "\n",
      "         [[3.3387e-04],\n",
      "          [4.8458e-05],\n",
      "          [6.2835e-03],\n",
      "          ...,\n",
      "          [2.0727e-05],\n",
      "          [5.6301e-01],\n",
      "          [8.2175e-02]],\n",
      "\n",
      "         [[9.3177e-05],\n",
      "          [2.2328e-03],\n",
      "          [1.2303e-04],\n",
      "          ...,\n",
      "          [3.8822e-02],\n",
      "          [4.2945e-02],\n",
      "          [2.5178e-03]]]])\n",
      "qqs.shape before tokenizer torch.Size([1, 2136, 16, 1])\n",
      "out.shape torch.Size([1, 32784])\n",
      "mus.shape torch.Size([1, 16])\n",
      "tensor([[0.0086, 0.0567, 0.1034, 0.0694, 0.0242, 0.0463, 0.0562, 0.0357, 0.1796,\n",
      "         0.0426, 0.0081, 0.0707, 0.0309, 0.0631, 0.1370, 0.0674]])\n",
      "pis.shape torch.Size([1, 16, 1024])\n",
      "tensor([[[ 0.4769, -0.2376,  0.4330,  ...,  0.2037, -0.1882,  0.6357],\n",
      "         [-0.0363,  0.3851, -0.3863,  ..., -0.8713,  0.2735, -0.7895],\n",
      "         [ 0.2554, -0.3595,  0.5590,  ..., -0.5768, -0.3417,  0.6880],\n",
      "         ...,\n",
      "         [ 0.3673,  0.2211, -0.9888,  ...,  0.2217, -0.4201, -0.2704],\n",
      "         [-1.1103, -0.0724, -0.0294,  ...,  0.8341, -0.0241, -0.4696],\n",
      "         [-1.0693, -0.0693,  0.1260,  ...,  0.9035,  0.3126,  0.0102]]])\n",
      "sigmas.shape torch.Size([1, 16, 1024])\n",
      "mus.shape after mus (16,)\n",
      "[0.0085914  0.05673845 0.10339829 0.06935471 0.02423741]\n",
      "qq.shape after qq (2136, 16)\n",
      "global_cluster_labels.shape (2136,)\n",
      "cluster_labels [15 14 10 14 13]\n",
      "2136 patches with soft assignments\n",
      "Prototype usage: [  6 122 258 143  35  90 126  48 430  92  10 151  58 127 311 129]\n",
      "Patch 0 @ coord (1344, 448) ‚Üí max proto: 15, score: 0.6904, full: [0.004 0.    0.    0.001 0.001 0.    0.    0.    0.    0.    0.052 0.\n",
      " 0.001 0.    0.25  0.69 ]\n",
      "Patch 1 @ coord (1568, 448) ‚Üí max proto: 14, score: 0.9092, full: [0.    0.    0.    0.003 0.    0.    0.    0.    0.    0.    0.001 0.\n",
      " 0.    0.    0.909 0.086]\n",
      "Patch 2 @ coord (1120, 672) ‚Üí max proto: 10, score: 0.8697, full: [0.005 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.87  0.\n",
      " 0.    0.    0.    0.125]\n",
      "Patch 3 @ coord (1344, 672) ‚Üí max proto: 14, score: 0.5543, full: [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.003 0.\n",
      " 0.    0.    0.554 0.441]\n",
      "Patch 4 @ coord (1568, 672) ‚Üí max proto: 13, score: 0.8557, full: [0.    0.    0.    0.011 0.001 0.013 0.    0.    0.    0.    0.004 0.\n",
      " 0.001 0.856 0.096 0.018]\n",
      "Patch 0 @ coord (1344, 448) ‚Üí max proto: 836, score: 1.0431, full: [ 0.477 -0.238  0.433 ...  0.204 -0.188  0.636]\n",
      "Patch 1 @ coord (1568, 448) ‚Üí max proto: 427, score: 1.2744, full: [-0.036  0.385 -0.386 ... -0.871  0.274 -0.789]\n",
      "Patch 2 @ coord (1120, 672) ‚Üí max proto: 213, score: 1.2100, full: [ 0.255 -0.36   0.559 ... -0.577 -0.342  0.688]\n",
      "Patch 3 @ coord (1344, 672) ‚Üí max proto: 1020, score: 1.2132, full: [ 0.406 -0.237  0.569 ... -0.038 -0.044  0.49 ]\n",
      "Patch 4 @ coord (1568, 672) ‚Üí max proto: 85, score: 1.1003, full: [ 0.215 -0.22   0.35  ...  0.186  0.254  0.849]\n",
      "Patch 0 @ coord (1344, 448) ‚Üí max proto: 836, score: 1.0431, full: [ 0.477 -0.238  0.433 ...  0.204 -0.188  0.636]\n",
      "Patch 1 @ coord (1568, 448) ‚Üí max proto: 427, score: 1.2744, full: [-0.036  0.385 -0.386 ... -0.871  0.274 -0.789]\n",
      "Patch 2 @ coord (1120, 672) ‚Üí max proto: 213, score: 1.2100, full: [ 0.255 -0.36   0.559 ... -0.577 -0.342  0.688]\n",
      "Patch 3 @ coord (1344, 672) ‚Üí max proto: 1020, score: 1.2132, full: [ 0.406 -0.237  0.569 ... -0.038 -0.044  0.49 ]\n",
      "Patch 4 @ coord (1568, 672) ‚Üí max proto: 85, score: 1.1003, full: [ 0.215 -0.22   0.35  ...  0.186  0.254  0.849]\n"
     ]
    }
   ],
   "source": [
    "from mil_models.tokenizer import PrototypeTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "h5_dir = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\uniextracted_mag5x_patch224_fp\\feats_h5'\n",
    "h5_feats_path = os.path.join(h5_dir, 'FA 47 B1.h5')\n",
    "# 1. Load patch features\n",
    "with h5py.File(h5_feats_path, 'r') as h5:\n",
    "    coords = h5['coords'][:]\n",
    "    feats = torch.Tensor(h5['features'][:])  # shape: [N, D]\n",
    "\n",
    "    feats = feats - feats.mean(dim=0)  # Center features\n",
    "    feats = feats / (feats.std(dim=0) + 1e-6)  # Scale features\n",
    "    print(\"Normalized feature stats - Mean:\", feats.mean().item(), \"Std:\", feats.std().item())\n",
    "    # print shape of feats and coords\n",
    "    print('feats.shape', feats.shape)  # debug\n",
    "\n",
    "# og code\n",
    "with torch.inference_mode():\n",
    "    info = panther_encoder.representation(feats.unsqueeze(dim=0))\n",
    "    qqs = info['qq']\n",
    "    # ---------\n",
    "    # After getting qq, before argmax:\n",
    "    print(\"Assignment scores before argmax (first 5 patches):\")\n",
    "    print(qqs[:5])  # Should show soft values if working properly\n",
    "\n",
    "    # Check if values are actually one-hot or just very close\n",
    "    # print(\"Unique values in qqs:\", np.unique(qqs.round(decimals=3)))\n",
    "   \n",
    "    print('qqs.shape before tokenizer', qqs.shape) # debug\n",
    "    # print('qqs before tokenizer', qqs)\n",
    "    out = info['repr']\n",
    "    print('out.shape', out.shape) # debug\n",
    "    tokenizer = PrototypeTokenizer(p=16, out_type='allcat')\n",
    "    mus, pis, sigmas = tokenizer.forward(out)\n",
    "    print('mus.shape', mus.shape)  # debug\n",
    "    print(mus)\n",
    "    print('pis.shape', pis.shape)  # debug\n",
    "    print(pis)\n",
    "    print('sigmas.shape', sigmas.shape)  # debug\n",
    "    mus = mus[0].detach().cpu().numpy()\n",
    "    print('mus.shape after mus', mus.shape)  # debug\n",
    "    print(mus[:5])  # debug\n",
    "    qq = qqs[0,:,:,0].cpu().numpy()\n",
    "    print('qq.shape after qq', qq.shape)  # debug\n",
    "    global_cluster_labels = qq.argmax(axis=1)\n",
    "    print('global_cluster_labels.shape', global_cluster_labels.shape)  # debug\n",
    "    print('cluster_labels', global_cluster_labels[:5])  # debug\n",
    "print(len(qq), \"patches with soft assignments\")\n",
    "# Check how many prototypes get used in your data\n",
    "unique_assignment_counts = np.bincount(global_cluster_labels)\n",
    "print(\"Prototype usage:\", unique_assignment_counts)\n",
    "\n",
    "# If >90% patches assign to <3 prototypes, needs modification\n",
    "\n",
    "for i in range(min(5, len(qq))):\n",
    "    coord = coords[i]\n",
    "    scores = qq[i]\n",
    "    max_idx = scores.argmax()\n",
    "    print(f\"Patch {i} @ coord {tuple(coord)} ‚Üí max proto: {max_idx}, score: {scores[max_idx]:.4f}, full: {np.round(scores, 3)}\")\n",
    "\n",
    "# Ensure pis is [N, p] numpy array\n",
    "if isinstance(pis, torch.Tensor):\n",
    "    pis_np = pis.detach().cpu().numpy()\n",
    "    if pis_np.ndim == 3:\n",
    "        pis_np = pis_np[0]\n",
    "else:\n",
    "    pis_np = pis\n",
    "\n",
    "for i in range(min(5, len(qq))):\n",
    "    coord = coords[i]\n",
    "    scores = pis_np[i]\n",
    "    max_idx = scores.argmax()\n",
    "    print(f\"Patch {i} @ coord {tuple(coord)} ‚Üí max proto: {max_idx}, score: {scores[max_idx]:.4f}, full: {np.round(scores, 3)}\")\n",
    "\n",
    "for i in range(min(5, len(pis_np))):\n",
    "    coord = coords[i]\n",
    "    scores = pis_np[i]\n",
    "    max_idx = scores.argmax()\n",
    "    print(f\"Patch {i} @ coord {tuple(coord)} ‚Üí max proto: {max_idx}, score: {scores[max_idx]:.4f}, full: {np.round(scores, 3)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panther",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
