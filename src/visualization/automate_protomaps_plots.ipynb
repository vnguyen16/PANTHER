{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# import openslide\n",
    "import torch\n",
    "import pandas as pd\n",
    "from prototype_visualization_utils import get_panther_encoder, visualize_categorical_heatmap, get_mixture_plot, get_default_cmap\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from mil_models.tokenizer import PrototypeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Loaded config path: C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs\\PANTHER_fa_pt\\config.json\n",
      "üìå Loaded config_dict from JSON: {'in_dim': 1024, 'n_classes': 2, 'heads': 1, 'em_iter': 1, 'tau': 0.001, 'ot_eps': 0.1, 'n_fc_layers': 0, 'dropout': 0.25, 'out_type': 'allcat', 'out_size': 8, 'load_proto': False, 'proto_path': '.', 'fix_proto': False}\n"
     ]
    }
   ],
   "source": [
    "### Loading PANTHER Encoder\n",
    "proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_k=0\\prototypes\\prototypes_c16_uni_kmeans_num_1.0e+06.pkl' # 5x uni\n",
    "# proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_10x_k=0\\prototypes\\prototypes_c16_uniextracted_mag10x_patch224_fp_kmeans_num_1.0e+06.pkl' # 10x uni\n",
    "# proto_path = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\splits\\FA_PT_2.5x_k=0\\prototypes\\prototypes_c16_uniextracted_mag2.5x_patch224_fp_kmeans_num_1.0e+06.pkl' # 2.5x uni\n",
    "# , model_config='PANTHER_fa_pt' out_type='allcat', \n",
    "panther_encoder = get_panther_encoder(in_dim=1024, p=16, proto_path=proto_path, config_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\configs', model_config='PANTHER_fa_pt', out_type='allcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FA_47_B1...\n",
      "Processing FA_57B...\n",
      "Processing PT_41_B...\n",
      "‚úÖ All visualizations saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from prototype_visualization_utils import get_default_cmap, get_mixture_plot  # make sure these exist\n",
    "\n",
    "# Setup paths\n",
    "feats_h5_dir = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide'\n",
    "save_root = r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations'\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "# Settings\n",
    "patch_size = 224\n",
    "alpha = 1\n",
    "scale = 0.25\n",
    "\n",
    "# Loop through all h5 feature files\n",
    "for fname in os.listdir(feats_h5_dir):\n",
    "    if not fname.endswith('.h5'):\n",
    "        continue\n",
    "\n",
    "    slide_id = fname.replace('.h5', '').replace(' ', '_')\n",
    "    h5_path = os.path.join(feats_h5_dir, fname)\n",
    "    slide_dir = os.path.join(save_root, slide_id)\n",
    "    os.makedirs(slide_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing {slide_id}...\")\n",
    "\n",
    "    # Load features and coords\n",
    "    with h5py.File(h5_path, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # Inference\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()\n",
    "        out = info['repr']\n",
    "\n",
    "        tokenizer = PrototypeTokenizer(out_type='allcat', p=qq.shape[1])\n",
    "        mus, pis, sigmas = tokenizer.forward(out)\n",
    "        mus = mus[0].detach().cpu().numpy()\n",
    "        cluster_labels = qq.argmax(axis=1)\n",
    "\n",
    "    # Normalize coordinates\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    coords -= np.array([x_min, y_min])\n",
    "    max_x, max_y = coords.max(axis=0) + patch_size\n",
    "    canvas_w, canvas_h = int(max_x), int(max_y)\n",
    "\n",
    "    # Draw prototype map\n",
    "    canvas = Image.new('RGBA', (canvas_w, canvas_h), (255, 255, 255, 255))\n",
    "    draw = ImageDraw.Draw(canvas, 'RGBA')\n",
    "    cmap = get_default_cmap(int(cluster_labels.max()) + 1)\n",
    "\n",
    "    for (x, y), label in zip(coords, cluster_labels):\n",
    "        color = cmap[label]\n",
    "        rgba = color + (int(255 * alpha),)\n",
    "        draw.rectangle([x, y, x + patch_size, y + patch_size], fill=rgba)\n",
    "\n",
    "    if scale < 1.0:\n",
    "        canvas = canvas.resize((int(canvas_w * scale), int(canvas_h * scale)))\n",
    "    canvas.save(os.path.join(slide_dir, 'prototype_map.png'))\n",
    "\n",
    "    # Save mixture plot\n",
    "    mixture_plot = get_mixture_plot(mus)\n",
    "    mixture_plot.savefig(os.path.join(slide_dir, 'mixture_plot.png'), bbox_inches='tight')\n",
    "    plt.close(mixture_plot)  # to avoid plot accumulation\n",
    "\n",
    "print(\"‚úÖ All visualizations saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_k_patches_per_prototype_from_qq(\n",
    "    h5_feats_fpath,\n",
    "    patch_dir,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224,\n",
    "    save_path=None\n",
    "):\n",
    "    import glob\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import h5py\n",
    "    import os\n",
    "\n",
    "    # Load patch-level features\n",
    "    with h5py.File(h5_feats_fpath, 'r') as h5:\n",
    "        coords = h5['coords'][:]\n",
    "        feats = torch.Tensor(h5['features'][:])\n",
    "\n",
    "    # Get prototype assignments\n",
    "    with torch.inference_mode():\n",
    "        info = panther_encoder.representation(feats.unsqueeze(0))\n",
    "        qq = info['qq'][0, :, :, 0].cpu().numpy()  # shape: (N, p)\n",
    "\n",
    "    n_patches, n_protos = qq.shape\n",
    "\n",
    "    # Select top-k patches per prototype (skip inactive prototypes)\n",
    "    proto_to_indices = {}\n",
    "    for proto in range(n_protos):\n",
    "        proto_scores = qq[:, proto]\n",
    "        if np.max(proto_scores) < 1e-5:  # Skip prototypes with no significant activation\n",
    "            continue\n",
    "\n",
    "        nonzero_indices = np.where(proto_scores > 1e-3)[0]\n",
    "        if len(nonzero_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        sorted_indices = nonzero_indices[np.argsort(-proto_scores[nonzero_indices])]\n",
    "        proto_to_indices[proto] = sorted_indices[:top_k]\n",
    "\n",
    "    active_protos = sorted(proto_to_indices.keys())\n",
    "    if len(active_protos) == 0:\n",
    "        print(\"‚ö†Ô∏è No active prototypes found in this slide.\")\n",
    "        return\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(len(active_protos), top_k, figsize=(top_k * 3, len(active_protos) * 3))\n",
    "    if len(active_protos) == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "    for row_idx, proto_idx in enumerate(active_protos):\n",
    "        indices = proto_to_indices[proto_idx]\n",
    "        for col_idx in range(top_k):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            if col_idx >= len(indices):\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch_idx = indices[col_idx]\n",
    "            x, y = coords[patch_idx]\n",
    "\n",
    "            pattern = f'*_x{int(x)}_y{int(y)}.npy'\n",
    "            matches = glob.glob(os.path.join(patch_dir, pattern))\n",
    "            if not matches:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            patch = np.load(matches[0])\n",
    "            ax.imshow(patch.astype(np.uint8))\n",
    "            if col_idx == 0:\n",
    "                ax.set_title(f'Proto {proto_idx}')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Saved top-k patches visualization to {save_path}\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def run_all_patch_visualizations(\n",
    "    feats_h5_dir,\n",
    "    patch_root,\n",
    "    csv_path,\n",
    "    save_root,\n",
    "    panther_encoder,\n",
    "    top_k=4,\n",
    "    patch_size=224\n",
    "):\n",
    "    \"\"\"\n",
    "    Automates prototype patch visualization across slides using Panther qq assignments.\n",
    "\n",
    "    Args:\n",
    "        feats_h5_dir (str): Path to the directory containing .h5 feature files.\n",
    "        patch_root (str): Root path to the patch directory (organized by magnification/class).\n",
    "        csv_path (str): Path to CSV file with columns ['Filename', 'Class', 'Magnification'].\n",
    "        save_root (str): Directory where visualization images will be saved.\n",
    "        panther_encoder (torch.nn.Module): Trained Panther encoder model.\n",
    "        top_k (int): Number of top patches to visualize per prototype.\n",
    "        patch_size (int): Size of each patch (default: 224).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['Filename'] = df['Filename'].str.strip()\n",
    "\n",
    "    for h5_file in os.listdir(feats_h5_dir):\n",
    "        if not h5_file.endswith('.h5'):\n",
    "            continue\n",
    "\n",
    "        slide_id = h5_file.replace('.h5', '').strip()\n",
    "\n",
    "        row = df[df['Filename'] == slide_id]\n",
    "        if row.empty:\n",
    "            print(f\"‚ö†Ô∏è Slide {slide_id} not found in metadata CSV.\")\n",
    "            continue\n",
    "\n",
    "        class_label = row['Class'].values[0]\n",
    "        magnification = row['Magnification'].values[0]\n",
    "\n",
    "        h5_feats_fpath = os.path.join(feats_h5_dir, h5_file)\n",
    "        patch_dir = os.path.join(patch_root, f\"{magnification}x\", class_label, slide_id)\n",
    "\n",
    "        if not os.path.isdir(patch_dir):\n",
    "            print(f\"‚ùå Patch directory not found: {patch_dir}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"‚úÖ Processing: {slide_id} | Class: {class_label} | Mag: {magnification}x\")\n",
    "\n",
    "        # Optional: organize outputs per slide\n",
    "        slide_dir = os.path.join(save_root, slide_id.replace(' ', '_'))\n",
    "        os.makedirs(slide_dir, exist_ok=True)\n",
    "        save_path = os.path.join(slide_dir, 'top_patches.png')\n",
    "\n",
    "        try:\n",
    "            visualize_top_k_patches_per_prototype_from_qq(\n",
    "                h5_feats_fpath=h5_feats_fpath,\n",
    "                patch_dir=patch_dir,\n",
    "                panther_encoder=panther_encoder,\n",
    "                top_k=top_k,\n",
    "                patch_size=patch_size,\n",
    "                save_path=save_path\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {slide_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processing: FA 47 B1 | Class: FA | Mag: 40x\n",
      "Saved top-k patches visualization to C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations\\FA_47_B1\\top_patches.png\n",
      "‚úÖ Processing: FA 57B | Class: FA | Mag: 20x\n",
      "Saved top-k patches visualization to C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations\\FA_57B\\top_patches.png\n",
      "‚úÖ Processing: PT 41 B | Class: PT | Mag: 20x\n",
      "Saved top-k patches visualization to C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations\\PT_41_B\\top_patches.png\n"
     ]
    }
   ],
   "source": [
    "run_all_patch_visualizations(\n",
    "    feats_h5_dir=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide',\n",
    "    patch_root=r'C:\\Users\\Vivian\\Documents\\CONCH\\all_patches\\patches_5x',\n",
    "    csv_path=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\src\\visualization\\slides_list.csv',\n",
    "    save_root=r'C:\\Users\\Vivian\\Documents\\PANTHER\\PANTHER\\features\\test_slide\\visualizations',\n",
    "    panther_encoder=panther_encoder,\n",
    "    top_k=4\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panther",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
